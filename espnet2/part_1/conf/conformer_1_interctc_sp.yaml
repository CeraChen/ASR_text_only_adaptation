batch_type: numel
batch_bins: 6650000 #6562500
accum_grad: 1
max_epoch: 100
patience: none

best_model_criterion:
-   - valid
    - loss
    - min
-   - valid
    - cer_ctc
    - min
keep_nbest_models: 10

encoder: conformer
encoder_conf:
    output_size: 256
    attention_heads: 8
    linear_units: 2048
    num_blocks: 18
    dropout_rate: 0.1
    positional_dropout_rate: 0.1
    attention_dropout_rate: 0.1
    input_layer: conv2d
    normalize_before: true
    interctc_layer_idx: [6,12]
    interctc_use_conditioning: true

#use_adapter: false
#training_step: 3
#adapter: conformer
#adapter_conf:
#    input_size: 1
#    output_size: 512
#    attention_heads: 8
#    linear_units: 2048
#    num_blocks: 6
#    dropout_rate: 0.1
#    attention_dropout_rate: 0.1
#    normalize_before: trueodel_conf:
#    ctc_weight: 1.0
#    interctc_weight: 0.5
#    lsm_weight: 0.1
#    length_normalized_loss: false

optim: adam
optim_conf:
    lr: 0.0013 #5
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 40000 #25000
